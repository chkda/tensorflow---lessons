{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...    28x19  28x20  \\\n0      7    0    0    0    0    0    0    0    0    0  ...        0      0   \n1      2    0    0    0    0    0    0    0    0    0  ...        0      0   \n2      1    0    0    0    0    0    0    0    0    0  ...        0      0   \n3      0    0    0    0    0    0    0    0    0    0  ...        0      0   \n4      4    0    0    0    0    0    0    0    0    0  ...        0      0   \n\n   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n0      0      0      0      0      0      0      0      0  \n1      0      0      0      0      0      0      0      0  \n2      0      0      0      0      0      0      0      0  \n3      0      0      0      0      0      0      0      0  \n4      0      0      0      0      0      0      0      0  \n\n[5 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "#loading the csv file\n",
    "data = pd.read_csv('F:/my files/python files/neural networks/Tensorflow lessons/Dataset/mnist_test.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  1x10  ...    28x19  28x20  \\\n0    0    0    0    0    0    0    0    0    0     0  ...        0      0   \n1    0    0    0    0    0    0    0    0    0     0  ...        0      0   \n2    0    0    0    0    0    0    0    0    0     0  ...        0      0   \n3    0    0    0    0    0    0    0    0    0     0  ...        0      0   \n4    0    0    0    0    0    0    0    0    0     0  ...        0      0   \n\n   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n0      0      0      0      0      0      0      0      0  \n1      0      0      0      0      0      0      0      0  \n2      0      0      0      0      0      0      0      0  \n3      0      0      0      0      0      0      0      0  \n4      0      0      0      0      0      0      0      0  \n\n[5 rows x 784 columns]\n   0  1  2  3  4  5  6  7  8  9\n0  0  0  0  0  0  0  0  1  0  0\n1  0  0  1  0  0  0  0  0  0  0\n2  0  1  0  0  0  0  0  0  0  0\n3  1  0  0  0  0  0  0  0  0  0\n4  0  0  0  0  1  0  0  0  0  0\n<class 'pandas.core.frame.DataFrame'>\n<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "#extracting inputs and targets from file\n",
    "labels = data['label']\n",
    "labels = pd.get_dummies(labels, prefix=None)\n",
    "pixels = data.iloc[:, 1:785]\n",
    "print(pixels.head())\n",
    "print(labels.head())\n",
    "print(type(pixels))\n",
    "print(type(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n<class 'numpy.ndarray'>\n[[0 0 0 ..., 0 0 0]\n [0 0 0 ..., 0 0 0]\n [0 0 0 ..., 0 0 0]\n [0 0 0 ..., 0 0 0]\n [0 0 0 ..., 0 0 0]]\n[[0 0 0 0 0 0 0 1 0 0]\n [0 0 1 0 0 0 0 0 0 0]\n [0 1 0 0 0 0 0 0 0 0]\n [1 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 1 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#converting datatype from pandas to a numpy array\n",
    "labels = labels.values\n",
    "pixels = pixels.values\n",
    "print(type(pixels))\n",
    "print(type(labels))\n",
    "print(pixels[:5])\n",
    "print(labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating batches for dataset\n",
    "class create_dataset:\n",
    "    \n",
    "    def __init__(self, x_train, y_train, x_val, y_val):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_val = x_val\n",
    "        self.y_val = y_val\n",
    "        \n",
    "    def get_batch(self, batch_size):\n",
    "        data = self.x_train\n",
    "        lab = self.y_train\n",
    "        feat = tf.data.Dataset.from_tensor_slices(data)\n",
    "        op = tf.data.Dataset.from_tensor_slices(lab)\n",
    "        tot_data = tf.data.Dataset.zip((feat, op))\n",
    "        batched_data = tot_data.repeat().batch(batch_size)\n",
    "        iterator = batched_data.make_initializable_iterator()\n",
    "        sess = tf.InteractiveSession()\n",
    "        sess.run(iterator.initializer)\n",
    "        next_batch = iterator.get_next()\n",
    "        next_batch = sess.run(next_batch)\n",
    "        sess.close()\n",
    "        return next_batch\n",
    "    \n",
    "    def val_data(self):\n",
    "        sess = tf.InteractiveSession()\n",
    "        data = self.x_val\n",
    "        lab = self.y_val\n",
    "        size = len(lab)\n",
    "        dat = tf.data.Dataset.from_tensor_slices(data)\n",
    "        labe = tf.data.Dataset.from_tensor_slices(lab)\n",
    "        tot = tf.data.Dataset.zip((dat, labe))\n",
    "        tot_data = tot.repeat().batch(size)\n",
    "        iterator = tot_data.make_initializable_iterator()\n",
    "        sess.run(iterator.initializer)\n",
    "        val_data = iterator.get_next()\n",
    "        val_data = sess.run(val_data)\n",
    "        sess.close()\n",
    "        return val_data\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = 4000\n",
    "tot_size = len(data)\n",
    "siz = tot_size-val_size\n",
    "x_tr = pixels[:siz]\n",
    "x_vl = pixels[siz:]\n",
    "y_tr = labels[:siz]\n",
    "y_vl = labels[siz:]\n",
    "mnist = create_dataset(x_tr, y_tr, x_vl, y_vl)\n",
    "train_x, train_y = mnist.get_batch(50)\n",
    "val_x, val_y = mnist.val_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 784)\n(50, 10)\n(4000, 784)\n(4000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(val_x.shape)\n",
    "print(val_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code snippets gives a detailed insight into how can one create his/her own dataset in tensorflow when you are provided with csv type dataset. First we extract\n",
    "the data from file using pandas then convert it into numpy array. After that we perform create a class to help us creating batches of dataset and validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
